# Job Training Program Evaluation Model

This project presents an end-to-end machine learning pipeline to evaluate outcomes from a real-world job training program. The analysis, built entirely in a Jupyter notebook, uses tree-based models to uncover which factors contribute to participant success and extract interpretable insights for policy and program design.

## What’s Inside:

• A complete walkthrough using tree-based models (e.g., Random Forest or Gradient Boosting)  
• Feature selection and engineering based on participant and program characteristics  
• Model training, validation, and interpretation  
• Visualizations and explainability tools for practical decision support  
• Clear code, outputs, and commentary aligned with applied data science practices  

## Model Highlights:

• Predicts training success or outcome scores using demographics, prior experience, and program duration  
• Handles categorical and numerical features via encoding and scaling  
• Extracts interpretable feature importances to inform resource allocation  
• Provides evidence-backed suggestions for improving training effectiveness  

## Why You Should Check It Out:

Whether you're interested in labor economics, social impact analysis, or just want to see a well-structured ML notebook applied to human development programs—this project is a clean and interpretable example.

## Files Included:

• `job_training_analysis.ipynb` — Full analysis and modeling walkthrough  
• `requirements.txt` — All required packages  
• `lalonde.csv` — Cleaned dataset (assumed source)  

## Get Started:

Clone the repo:  
`https://github.com/Stefanjafry/job-training-evaluation`

Install requirements:  

pip install -r requirements.txt

Launch Notebook:
job_training_analysis.ipynb

License:
This project is licensed under the MIT License. You are free to use, modify, and distribute the code.
